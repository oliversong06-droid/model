# ai_predictor/dataset.py

from __future__ import annotations
import os
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader, random_split

# Default temporal window settings (can be adjusted)
T_IN = 10   # how many past steps we feed into the model
T_OUT = 5   # how many future steps we want to predict


class OilSpillSequenceDataset(Dataset):
    """
    Dataset for synthetic sequences generated by make_synthetic_data.py.

    Expected .npz structure:
        features: (N, T, C, H, W)
        C = 3 : oil, U, V

    __getitem__ returns:
        X: (T_IN, C, H, W)
        y: (T_OUT, 1, H, W)   # target is oil channel only
    """

    def __init__(
        self,
        npz_path: str,
        t_in: int = T_IN,
        t_out: int = T_OUT,
    ):
        super().__init__()
        if not os.path.isfile(npz_path):
            raise FileNotFoundError(f"npz file not found: {npz_path}")

        data = np.load(npz_path)
        if "features" not in data:
            raise KeyError("npz file must contain 'features' array")

        self.features = data["features"].astype(np.float32)  # (N, T, C, H, W)
        self.t_in = int(t_in)
        self.t_out = int(t_out)

        self.N, self.T, self.C, self.H, self.W = self.features.shape
        if self.T < self.t_in + self.t_out:
            raise ValueError(
                f"Sequence length T={self.T} is too short for T_IN+T_OUT={self.t_in + self.t_out}"
            )

    def __len__(self) -> int:
        # each sequence is treated as one sample
        return self.N

    def __getitem__(self, idx: int):
        seq = self.features[idx]  # (T, C, H, W)

        X = seq[: self.t_in]                      # (T_IN, C, H, W)
        y_oil = seq[self.t_in:self.t_in + self.t_out, 0:1]  # (T_OUT, 1, H, W)

        X = torch.from_numpy(X)  # float32
        y = torch.from_numpy(y_oil)

        return X, y


def build_dataloaders(
    npz_path: str,
    batch_size: int = 4,
    val_ratio: float = 0.2,
    test_ratio: float = 0.1,
    t_in: int = T_IN,
    t_out: int = T_OUT,
    num_workers: int = 0,
):
    dataset = OilSpillSequenceDataset(npz_path, t_in=t_in, t_out=t_out)

    n_total = len(dataset)
    n_test = int(n_total * test_ratio)
    n_val = int(n_total * val_ratio)
    n_train = n_total - n_val - n_test

    train_set, val_set, test_set = random_split(
        dataset,
        [n_train, n_val, n_test],
        generator=torch.Generator().manual_seed(42),
    )

    train_loader = DataLoader(
        train_set,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        drop_last=True,
    )
    val_loader = DataLoader(
        val_set,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        drop_last=False,
    )
    test_loader = DataLoader(
        test_set,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        drop_last=False,
    )

    return train_loader, val_loader, test_loader


if __name__ == "__main__":
    # Quick smoke test
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    npz_path = os.path.join(base_dir, "data", "processed", "train_sequences.npz")

    train_loader, val_loader, test_loader = build_dataloaders(npz_path)

    for X, y in train_loader:
        print("X shape:", X.shape)  # (B, T_IN, C, H, W)
        print("y shape:", y.shape)  # (B, T_OUT, 1, H, W)
        break
